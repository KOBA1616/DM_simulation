# AI学習・対戦シミュレーションに関する現状分析レポート

本レポートでは、`dm_toolkit/ai/agent/mcts.py` (MCTS) および `dm_toolkit/ai/agent/transformer_model.py` (Transformer) を中心に、現在のAI学習基盤における課題点と解決策をまとめました。

## 1. MCTS (Monte Carlo Tree Search) における課題と解決策

| No. | 課題 (Problem) | 詳細 (Detail) | 解決策 (Solution) |
| :--- | :--- | :--- | :--- |
| 1 | **Python実装による実行速度** | 現在のMCTSは純粋なPythonで実装されており、ループ処理やオブジェクト生成のオーバーヘッドが非常に大きく、十分な探索回数を確保できません。 | コアロジック（特にSelectionとExpansion）をC++拡張モジュール (`dm_ai_module`) 側に移行するか、Cython/JITを用いて高速化する。 |
| 2 | **順次推論によるGPU非効率性** | `_expand` メソッド内で毎回個別に `network(tensor)` を呼び出しており、バッチ処理が行われていません。GPUの能力を活用できていません。 | リーフノードを一定数プールしてから一括で推論する「Batch MCTS」または「Virtual Loss」を用いた非同期並列探索を導入する。 |
| 3 | **完全情報仮定 (Cheating)** | 相手の手札を含む「真の状態」を用いて探索を行っており、実際の対戦環境（不完全情報）と乖離しています。 | 相手の手札をランダムなカードとしてサンプリングする「Determinization (PIMCTS)」または、隠れ情報を推論する「Information Set MCTS」を実装する。 |
| 4 | **状態クローンの高負荷** | 各シミュレーションステップで `node.state.clone()` (deep copy) を実行しており、これがプロファイリング上のボトルネックになる可能性が高いです。 | `clone` の代わりに、変更差分のみを適用・巻き戻し可能な `DoMove/UndoMove` インターフェースをエンジン側に実装する。 |
| 5 | **探索打ち切りの甘さ** | ゲーム終了 (`check_game_over`) まで探索を続ける仕様に見えますが、ループや長期戦に対する深さ制限と、その際の価値評価フォールバックが不十分です。 | 最大探索深さを設定し、到達時にネットワークのValue Headの値を報酬として返す処理を明確化する。 |
| 6 | **行動空間のフラット化** | 複雑な引数を持つカードゲームの行動を `ActionEncoder` で単純な整数インデックスに変換していますが、衝突や表現力不足のリスクがあります。 | 行動を (Source, Type, Target) などの階層的構造として扱い、ネットワーク側もそれに合わせた多頭出力 (Pointer Network等) に変更する。 |
| 7 | **報酬のスパース性** | 勝敗 (1/0/-1) のみが報酬となっており、長期的な戦略学習が進みにくい状態です。 | 盤面優位性（シールド差、マナ差など）に基づく中間報酬 (Dense Reward) を導入し、学習初期の収束を助ける（後に減衰させる）。 |
| 8 | **パス処理のハードコード** | `PASS` や `add_mana` に関する処理がMCTS内にハードコードされており、エンジンのフェーズロジック変更に脆弱です。 | エンジンの `PhaseManager` または `CommandSystem` に「可能な次の一手」を完全に委譲し、MCTS側は透過的に扱うように修正する。 |
| 9 | **ヒューリスティック・ロールアウトの欠如** | ネットワーク未学習時や探索外の領域において、ランダムプレイアウトよりもマシな「軽量ポリシー（ルールベース）」が存在しません。 | シンプルな攻撃優先・マナチャージ優先などの軽量ロジックを実装し、ロールアウト時の精度を底上げする。 |
| 10 | **データ型の不整合** | `dm_ai_module.TensorConverter` は通常 Float Tensor を返しますが、後述のTransformerは Integer Token を期待しているため、そのまま接続するとエラーになります。 | MCTS初期化時に、Transformer専用の `TokenConverter` (Int配列を返す) を明示的に注入する仕組みを徹底する。 |

## 2. Transformer Model (DuelTransformer) における課題と解決策

| No. | 課題 (Problem) | 詳細 (Detail) | 解決策 (Solution) |
| :--- | :--- | :--- | :--- |
| 1 | **入力データ型の不一致** | モデルは `nn.Embedding` 層を持ち Integer 入力を期待していますが、エンジンの標準出力は Float ベクトルである場合が多く、接続部分で型エラーまたは無意味な埋め込みが発生します。 | エンジン側にトークナイザ (`TokenConverter.encode_state` 等) を実装し、盤面を「カードIDのシーケンス」として出力するアダプタを整備する。 |
| 2 | **コンテキスト長の不足** | `max_len=200` に設定されていますが、デュエル・マスターズの盤面（マナ、墓地、バトルゾーン、手札）と履歴を含めると200トークンは容易に超過します。 | `max_len` を512以上に拡張し、Transformer-XLのような長いシーケンスに対応できるアーキテクチャ、または重要な情報のみを抽出するフィルタリングを導入する。 |
| 3 | **CLSトークン依存の設計** | Policy/Value Headが `x[:, 0, :]` (CLSトークン) を使用する設計ですが、入力データ生成時に必ず先頭に特殊トークンが付与される保証がコード上で確認できません。 | 入力パイプラインで明示的に `[CLS]` トークンを付与するか、Global Average Pooling に変更してトークン位置依存を解消する。 |
| 4 | **静的な位置埋め込み** | `pos_embedding` が学習可能な固定パラメータであり、学習時より長いシーケンスが来た場合に破綻します。 | 相対位置エンコーディング (Relative Positional Encoding) や RoPE (Rotary Positional Embeddings) を採用し、可変長シーケンスへの耐性を持たせる。 |
| 5 | **シナジー行列の計算コスト** | `SynergyGraph` によるバイアス計算は $O(N^2)$ のメモリと計算を要し、推論速度を低下させる要因になります。 | 学習初期にはこの機構を外し、ベースラインの性能を確認する。必要であれば、Self-AttentionのHeadの一部として組み込む形に簡略化する。 |
| 6 | **出力ヘッドの次元固定** | `action_dim` が固定されていますが、実際には動的な「有効な手（Legal Actions）」の中から選択する必要があります（Maskingが必要）。 | 出力層の直前で `Legal Action Mask` (無効な手のロジットを $-\infty$ にする) を適用する仕組みを `forward` メソッドまたは損失計算に追加する。 |
| 7 | **学習スクリプトの欠落** | `reinforcement_loop.py` から呼び出されるはずの `generate_training_data.py` がリポジトリ内に存在せず、自律的な学習ループを回すことができません。 | 自己対戦を行い、(State, Policy, Value) のセットを保存するデータ生成スクリプトを新規に実装する。 |
| 8 | **過学習のリスク** | レイヤ数6、次元数256などの設定は、学習データが少ない初期段階では過学習（Overfitting）する可能性が高いです。 | パラメータ数を減らした「Tiny」モデル構成を用意し、データ量が確保できるまではそちらで検証を行う。 |
| 9 | **マスキング処理の曖昧さ** | パディング（`padding_mask`）の処理が引数として存在しますが、MCTSからの呼び出し時に適切に長さ調整とマスク生成が行われているか不明瞭です。 | バッチ化された入力に対して正確にパディングマスクを作成・適用するユーティリティ関数を整備する。 |
| 10 | **Value Headの出力範囲** | `tanh` で $[-1, 1]$ を出力しますが、MCTS側でのバックプロパゲーションや報酬定義（$0, 1$ なのか $-1, 1$ なのか）と整合しているか確認が必要です。 | 報酬体系を $[-1, 1]$ (負け=-1, 勝ち=1) に統一し、テストケースで出力範囲の整合性を検証する。 |

## 結論

現状のシステムは「プロトタイプ」の域を出ておらず、実用的な学習を行うには **インフラ（データ生成・学習ループ）の整備** と **MCTS-Transformer間のインターフェース（特に型とマスク）の整合** が最優先事項です。特に `generate_training_data.py` の再実装と、整数トークンベースのState Converterの整備から着手することを推奨します。
