# システム説明書（研究要約・概要）

## 1. 研究要約（Abstract）
本研究は、トレーディングカードゲーム（TCG）であるデュエル・マスターズを対象に、データ駆動型シミュレータとCPU環境でも動作する軽量AIを統合した実験基盤を構築する。特に、Attention 機構に基づく行動候補の順位付け・枝刈りにより探索爆発を抑制し、限られた計算資源下でも探索を実用化することを狙う。システムは C++20 のルールエンジンと Python の学習・評価・GUIを接続し、自己対戦に基づくデータ収集と反復改善を可能にする（例: 学習設定の既定値は `config/train_config.yaml` に集約）。

## 2. 概要（Overview）
対象ゲームは、不完全情報と複雑な効果により分岐が急増し、探索爆発がCPU環境での主要ボトルネックとなる。本システムは、ルールに忠実な高速シミュレーションを基盤に、軽量推論と Attention による探索制御（候補削減・優先度付け）を組み合わせて、探索の計算量を抑えながら意思決定品質を向上させる。

システムは次の層から構成される。
- **C++ コアエンジン層**: ゲーム状態管理、合法手生成、効果解決、探索（例: MCTS）および並列実行
- **Python ツール層**: 学習ループ（例: PyTorch）、データ管理、評価スクリプト、GUI（カードエディタ等）
- **データ層**: カード定義・デッキ・シナリオ等をJSONで管理し、データ駆動で効果処理を記述

## 3. 目的（Objectives）
本研究はAI開発を中心に、以下の目的を設定する。
1. **CPU環境前提の軽量推論設計**: 入力特徴量の圧縮とモデル小型化（パラメータ数・演算量の上限設定）により、GPU非依存で推論できる実装経路を確立する。
2. **Attention による探索制御**: 盤面表現と行動候補の対応を学習し、候補の順位付け（Top-$k$）・確率的サンプリング・枝刈りを組み合わせて、探索爆発（分岐数増大）を抑制する。
3. **学習・評価サイクルの運用化**: 自己対戦データ収集、学習、検証を反復可能にし、CPU上での推論レイテンシ、探索ノード数、勝率等の指標で改善を追跡する。
4. **実験の反復可能性の確保**: 設定・ログ・評価指標を明確化し、モデルや探索パラメータの変更が性能に与える影響を追跡できる状態を維持する。

### 3.1 代表的な数値設定と根拠（Default Parameters）
本書で言及する「探索上限」「学習条件」「CPU運用」の前提は、実装内で実際に利用されている設定値・既定引数に基づく。代表例を以下に示す。

- **MCTS（学習時の既定値）**: 1手あたりシミュレーション回数 $25$、$c_{puct}=1.0$（`config/train_config.yaml`）
- **探索ノイズ（学習時）**: Dirichlet $\alpha=0.3$、$\epsilon=0.25$（`config/train_config.yaml`）
- **学習ループ（既定値）**: batch size $32$、learning rate $1\times 10^{-3}$、epochs $1$、iterations $10$、1反復あたりゲーム数 $10$（`config/train_config.yaml`）
- **バッチ推論（既定値）**: MCTSバッチサイズ $8$（`config/train_config.yaml`）
- **性能検証（スクリプト既定値）**: MCTS sims $800$、batch size $32$、threads $4$（`python/training/verify_performance.py` の `verify()` 既定引数）
- **入力表現の規模（実装上の根拠）**: flat特徴量長のフォールバックは $205$（`python/training/verify_performance.py`）、Transformer系列の最大系列長は $200$（同ファイル内 `max_seq_len`）

上記は「目標値」ではなく「再現可能な既定条件」である。実験ではこれらを基準点として、候補削減率や探索ノード数、CPU上の推論レイテンシを併記し、パラメータ変更の影響を検証する。

## 4. 背景（Background）
TCGの意思決定は、大規模な状態・行動空間と不完全情報、ならびに対象選択・条件分岐により複雑である。合法手生成の分岐増大は探索爆発を引き起こし、CPU環境では試行回数が制約される。本研究は、軽量推論と Attention による探索制御を、性能重視のルールエンジンと統合し、実験の回転率と再現性を両立する実装基盤を目指す。

## 5. 結果（Results）
本研究で構築したシステムにより、以下の成果を得た。
- **ハイブリッド実装の成立**: C++20 のコアエンジンと Python ツール群を統合し、探索・学習・GUIを同一ワークスペースで運用可能とした。
- **データ駆動の効果処理**: カード定義をJSONに集約し、効果を条件（Condition）とアクション（Action）のツリーとして表現する枠組みを整備した。
- **探索・学習の実験運用の整備**: 学習・評価・可視化の経路を用意し、自己対戦データに基づく反復改善を行える構成とした。

## 6. 考察（Discussion）
本システムは、ルール実行（C++）と学習・運用（Python）を分離し、反復実験に適した構成を採用する。主要課題はCPU環境における探索爆発であり、軽量推論と Attention による候補制御を組み合わせることで、計算資源と意思決定品質のトレードオフを管理可能にする。

AI機能の実装における基本方針は「探索を強くする前に、探索を成立させる」ことである。具体的には、(1) まずルールに忠実な合法手生成を前提に分岐の原因を分析し、(2) 次にCPUでの許容計算量を基準として探索の上限（ノード数・深さ・候補数）を固定し、(3) 最後に Attention により候補を優先度付けして、上限内でより良い手を探索できるようにする。

また、Attention は「局面全体を精緻に理解する万能器」ではなく、「分岐の多い局面で計算資源を集中させるためのスコアラー」として位置付ける。候補削減により探索の見落としが増える可能性があるため、Top-$k$ と確率的サンプリングを併用し、多様性を残したまま探索幅を制御する。評価は勝率だけでなく、CPU上の推論レイテンシ、探索ノード数、候補削減率などの計測可能な指標を併置し、性能と品質の均衡点を探索する。

### 6.1 差別化（Contribution）
本研究の差別化点は、Attention を「大規模モデルによる高精度予測」の中心機構としてではなく、「探索に投入すべき計算資源の配分器」として用いる点にある。軽量推論はCPU上で継続的に回せる計算量に制約し、Attention により行動候補の重要度を推定して Top-$k$ と確率的サンプリングを組み合わせることで、探索幅を抑えつつ探索の多様性を保持する。これにより、GPUを前提としない環境でも探索爆発を制御し、限られたノード予算の下で意思決定品質を維持・改善する設計方針を提示する。

この「ノード予算」の具体例として、学習設定では 1手あたり $25$ シミュレーション（`config/train_config.yaml`）、性能検証では $800$ シミュレーション（`python/training/verify_performance.py`）が既定値として用意されている。すなわち、同一の推論器を用いつつも、CPU環境で許容される計算量に応じて探索規模を可変にし、Attention で「どの候補にその計算量を割くか」を制御する点が実装上の差別化となる。

## 7. 今後の展望（Future Work）
今後の課題は以下に整理される。
1. **軽量AIの最適化**: 特徴量圧縮、モデルの蒸留・量子化、推論キャッシュ等により、CPU上でのレイテンシとスループットを改善する。
2. **Attention を用いた探索制御の高度化**: 重要度推定を用いた候補削減、段階的ビーム幅制御、局面依存の探索深さ調整などを導入し、探索爆発の再発を抑止する。
3. **不完全情報への強化**: Deck Inference や PIMC を含む推定・探索を高度化し、隠れ情報下での方策品質を改善する。
4. **品質保証の強化**: GUIスタブやテキスト生成等の残課題を縮減し、回帰を抑止するテスト体系を拡充する。
5. **編集・検証体験の改善**: カードエディタの検証機能、ルールテキスト生成、UI操作性を改善し、データ作成の生産性を高める。

なお、Transformer 系モデルの学習設定例として、$d_{model}=256$、head数 $8$、層数 $6$、最大系列長 $200$、語彙サイズ $1000$ が定義されている（`python/training/train_transformer_phase4.py`）。CPU向けの軽量化においては、これらの縮小や量子化を含めた計算量削減が検討対象となる。

---

## 付録A: 関連ドキュメント
- システム全体像・アーキテクチャ（開発者向け概要）
- AI要件定義（学習・推論・進化等の仕様）
- 開発ポリシー（開発フロー、品質保証方針）
