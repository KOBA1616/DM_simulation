# Status and Requirements Summary (要件定義書 00)

このドキュメントはプロジェクトの現在のステータス、実装済み機能、および次のステップの要件をまとめたマスタードキュメントです。

本要件定義書はShift-JISで記述することを前提とします（ツール制約によりファイルエンコードはUTF-8で保存されています）。

## 1. 概要 (Overview)

Duel Masters AI Simulatorは、C++による高速なゲームエンジンと、Python/PyTorchによるAlphaZeroベースのAI学習環境を統合したプロジェクトです。
現在、コアエンジンの実装フェーズ（Phase 0: Foundation）を完了し、AIの知能進化と自己学習エコシステムの構築（Phase 1-4）へと移行しています。

## 2. 現行システムステータス (Phase 0: Foundation)

### 2.1 コアエンジン (C++)
*   **基本ルール**: マナチャージ、召喚、攻撃、ブロック、シールドブレイク、勝利条件などの基本ゲームループを実装済み。
*   **高度なメカニクス**:
    *   **スタックシステム**: トリガー能力の待機と解決順序の制御。
    *   **多色・進化**: 多色カードのマナ支払い（バックトラック法）、進化クリーチャー、NEOクリーチャー、メテオバーン。
    *   **アクションシステム**: `GenericCardSystem` と `IActionHandler` によるモジュラーな効果処理。
    *   **効果実装**: サーチ、シールド追加、除去、ハンデス、革命チェンジ、ジャストダイバー、ハイパーエナジーなど。

### 2.2 AI & 学習基盤 (Python/C++)
*   **MCTS**: `dm::ai::MCTS` によるモンテカルロ木探索と並列実行 (`ParallelRunner`)。
*   **AlphaZero**: ResNetベースのニューラルネットワークと自己対戦データ収集パイプライン。
*   **PBT準備**: 複数のエージェントを戦わせる基盤の初期実装。

### 2.3 GUI & ツール (Python/PyQt6)
*   **カードエディタ Ver 2.0**: JSONデータの視覚的な作成・編集、ロジックツリー表示、変数リンク機能。
*   **シミュレーション**: 対戦の観戦、デバッグ機能、シナリオ実行。

### 2.4 特定された課題 (Identified Issues)
現在のコアエンジンにおける致命的な既知の不具合は解消されました。

※ 完了した詳細な実装タスク（Phase 0.5-1, Phase 6-8等）は `docs/00_Overview/99_Completed_Tasks_Archive.md` にアーカイブされています。

---

## 3. デュエル・マスターズAI 総合実装計画 (Phase 1-4)

これまでの議論（不完全情報への対応、リーサル判定、自己進化システム）をすべて統合した、デュエル・マスターズ特化型AIの**総合実装計画**を以下にまとめます。
この計画は、現在のC++コア（Phase 0）を基盤とし、**「負けない戦い方（Phase 1）」から「人間的な読み（Phase 2）」**、そして**「無限の成長（Phase 3）」**へと段階的に進化させるロードマップです。

### Phase 0.5: コアエンジンリファクタリング (Core Refactoring)
**ステータス**: 実装完了 (Completed)。詳細はアーカイブ (`docs/00_Overview/99_Completed_Tasks_Archive.md`) を参照。

### Phase 1: 確実性の確保（ロジック強化フェーズ）
**ステータス**: 実装完了 (Completed)。詳細はアーカイブ (`docs/00_Overview/99_Completed_Tasks_Archive.md`) を参照。

### Phase 2: 不完全情報の克服（PIMC実装フェーズ）

**目標**: 相手の手札・シールドが見えない前提で、人間のような「読み」と「ブラフ」への対応を実現する。

1.  **自己更新型推論システム (Self-Updating Inference System) の構築**
    *   **概要**: 公開情報から相手のデッキタイプと残りのカードを推定する。
    *   **実装内容**:
        *   `meta_decks.json`: 主要メタデッキの定義ファイル。
        *   **推論ロジック**: 相手のマナ・墓地の公開情報と `meta_decks.json` をマッチングさせ、デッキタイプ確率分布を算出する。
        *   **自動学習**: 自己対戦（Phase 3）のプロセスにおいて、AIが遭遇したデッキタイプやカード構成を学習し、`meta_decks.json` を自動的に更新・拡張する仕組みを導入。人間の介入なしに新環境に適応させる。

2.  **PIMC (Perfect Information Monte Carlo) の統合**
    *   **概要**: 推論に基づき、見えない領域をランダムに埋めた「仮想世界」を複数生成して探索する。
    *   **実装内容**:
        *   探索開始時に推論結果に基づいて $N$ 個の `GameState`（世界）をサンプリング生成。
        *   `ParallelRunner` を拡張し、各世界を並列スレッドで独立してMCTS探索。
        *   **MaxMinStrategy / Vote**: 全世界の探索結果を集計（Aggregate）し、最も「最悪ケースでも機能する」あるいは「平均的に最も良い」手を選択する。

### Phase 3: 自己進化エコシステムの構築（自動学習フェーズ）

**目標**: 人間が管理せずとも、AIが勝手に自己対戦を繰り返し、環境に合わせて進化し続けるループを確立する。

1.  **AlphaZeroサイクル + PBT (Population Based Training)**
    *   **概要**: 「放置可能な進化システム」の完成。
    *   **実装内容**:
        *   **自動ループ**: `RunAlphaZeroCycle.py` (仮) により以下のフローを完全自動化。
            *   `Collect` (自己対戦: 現行最強モデル vs 過去モデル/PBT集団)
            *   `Train` (学習: 収集データを用いたモデル更新)
            *   `Evaluate` (評価: Gatekeeperによる新旧対決と入れ替え判定)
        *   **リーグ戦 (PBT)**:
            *   単一のモデルではなく、複数の異なるハイパーパラメータ（攻撃重視、守備重視、リスク係数 $\alpha$ の違いなど）を持つエージェント群（Population）を維持。
            *   エージェント同士をリーグ戦形式で競わせ、優秀な個体のパラメータを継承・変異させて次世代を作る。
    *   **期待効果**: 寝ている間にPCを稼働させるだけで、AIがメタゲームの偏り（アグロ偏重など）を自律的に修正し、多様な戦術を獲得する。

2.  **詳細実装仕様: 世代管理システムとストレージ戦略 (Generation Management System)**
    *   PBT（Population Based Training）を見据えた、モデルとデッキの世代管理およびストレージ最適化の要件。
    *   **ディレクトリ構造 (Directory Structure)**:
        ```
        checkpoints/
          ├── production/          # 本番稼働用（現在の最強モデル）
          │    └── best_model.pth
          │
          ├── hall_of_fame/        # 殿堂入り（過去の強力なモデル、評価対戦用）
          │    ├── gen_0010.pth
          │    ├── gen_0050.pth
          │    └── gen_0100.pth
          │
          └── population/          # 進化中の個体群（一時保存、頻繁に入れ替わる）
               ├── agent_01/
               │    ├── gen_0005.pth
               │    └── deck.json
               └── agent_02/ ...
        ```
    *   **世代保持ポリシー (Retention Policy)**:
        *   **最新 (Latest)**: 各エージェントにつき、最新3世代のみ保持。
        *   **殿堂入り (Hall of Fame)**: 対数的間隔 (Gen 1, 2, 4, 8, ...) で永続保存し、多様性を維持する対戦相手として利用。
    *   **ストレージ管理**:
        *   学習データ (.npz) は最新の50万〜100万サンプル（スライディングウィンドウ）のみ保持し、自動削除する `cleanup_old_checkpoints()` を実装する。

### Phase 4: アーキテクチャの刷新（将来的な最適化）

**目標**: さらなる強さと計算効率の追求。

1.  **Linear Attention / DeepSets の導入**
    *   現在のCNN/ResNetベース（固定長入力）から、可変長のカードリストを効率的に扱えるアーキテクチャへ移行。
    *   カード枚数が増えても計算速度が落ちない軽量モデルにより、推論速度（NPS: Nodes Per Second）を向上させ、探索の深さを確保する。

### Phase 5: 将来的なAI拡張 (Future AI Refinement)

1.  **AIモデルの高度化 (PPO + LSTM)**
    *   Linear Attentionとは別のアプローチとして、強化学習の高度化を検討。
    *   **基本構成**: Actor-Critic (PPO) + LSTM。
    *   **入力層**: 盤面ベクトル + カード埋め込み + 墓地・マナのコンボパーツ密度。
    *   **学習戦略**: 模倣学習 -> 報酬シェイピング -> Action Masking。

## 4. 新規追加要件 (New Requirements)

### 4.1 ツインパクトカード実装支援 (GUI)
*   **目的**: カードエディタでのツインパクトカード作成を容易にする。
*   **仕様**:
    *   カードタイプ「ツインパクト」を選択した際、GUIレイアウトを自動的に変形させる。
    *   クリーチャー側と呪文側のデータを個別に、かつ1つのJSONとして編集可能な構造にする。

### 4.2 キーワード能力付与効果の実装
*   **目的**: 味方クリーチャーに「ブロッカー」や「スレイヤー」などを付与する効果の実装。
*   **仕様**: `GRANT_KEYWORD` アクションの実装と、継続的効果（Duration）の管理。

### 4.3 OpenMP有効化と並列処理最適化
*   **目的**: シミュレーション速度の向上。
*   **仕様**:
    *   CMakeでのOpenMP有効化。
    *   `ParallelRunner` およびMCTS探索におけるスレッド競合の排除とループ効率化。

### 4.4 敗北判定の遅延（ダイレクトアタック時）
*   **目的**: ダイレクトアタック時、防御側が「ニンジャ・ストライク」や「革命0トリガー」を使用可能にする。
*   **仕様**:
    *   シールド0枚での被弾時、即座に `LOSE` 判定を行わず、割り込み処理（リアクションウィンドウ）の解決を待つ。
    *   全ての処理終了後、依然として攻撃が通っている場合に敗北判定を行う。

### 4.5 GUIエラー修正
*   **目的**: アプリケーションの安定性向上。
*   **仕様**:
    *   GUI実行時に発生している `Traceback` および `AttributeError` の特定と修正。

### 4.6 カードテキスト自動生成機能 (Card Text Generator)
*   **目的**: カードエディタのプレビュー画面で、JSONデータに基づいた日本語のルールテキストを自動生成・表示し、カード作成の効率と正確性を向上させる。
*   **実装計画概要**:
    1.  **テキスト生成ロジックの実装 (`python/gui/editor/text_generator.py`)**
        *   カードデータ（JSON構造）を受け取り、日本語のルールテキストを生成する `CardTextGenerator` クラスを新規作成する。
        *   **キーワード変換**: `speed_attacker` → 「スピードアタッカー」などの単純変換を実装。
        *   **トリガー変換**: `ON_PLAY` → 「このクリーチャーが出た時、」などの定型文変換を実装。
        *   **アクション変換 (段階的実装)**:
            *   基本的なアクション（`DRAW_CARD`, `DESTROY`など）を日本語化。
            *   変数が絡む複雑な部分は、まず「変数の内容」を簡易表示する形式（例：「[変数:マナ文明数]」）で実装し、可読性を確保。
    2.  **カード編集画面への統合 (`python/gui/editor/forms/card_form.py`)**
        *   **プレビューエリアの追加**: `CardEditForm` の最下部に読み取り専用のテキストエリア (`QTextEdit`) を配置。
        *   **リアルタイム更新**: カードのパラメータ変更や、子要素（効果・アクション）の追加・変更を検知して、プレビューテキストを即座に再生成・表示する仕組みを構築。
        *   **データ再構築**: `CardEditForm` は通常自身のデータしか持たないが、プレビュー生成には「子要素（効果・アクション）」の情報も必要なため、ツリー構造から最新の全データを取得するヘルパー機能を実装。
