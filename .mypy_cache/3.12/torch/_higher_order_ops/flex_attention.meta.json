{"data_mtime":1766671106,"dep_hashes":["7c4e854dec0c84918e6bd524e880e7c9db90b36c","05d26fa985516f819f2ae1c49b6e1a129ba3d44f","ea96abd1b85d71fd4bacf90e42566b218108a657","72b57d1a38e59e6464ede3d56bf8f3f61ab25240","5800edf4d6c9f1a2df7344db1e16a197083b4b84","b708a50c62332b6d8a78f6ca83f66fea1268dbc2","25d0bb1f1a05173796e9e1518dd830a3e384de12","706568f1505f727f79da48475350c40bf17377cc","32e3f05ba6a7c2b2d238de68cc5f2f9edda4ab9b","0e936cde7c061ee28cd1f1593efea40ff6531cb3","2803465acd2471f91e0d3d33030a43d70bccb294","9402adce881967262cd085ded26bfdcc948db880","03a7f2a0d76cf938e2cfbde51320ea7f7010f907","7a160b1e936f38f725be214321ea0be83bc4d3ec","d1973c0e9bc3733a5841305c61ece75df2f37dbb","d85afe14f995e2ab331b7a97cda25985a4cf32d0","286450dfa69445e50787347e1282381910cecf6a","b9b49ee7ee62defded5d266fb47ecc26d50b22b4","7d6a0683091c74e334fe89f9f8692c6aea017dde","3c7f8d8ed52f3be3a8504877e49c26523d2dad76","0a06b1abdc58e2578cddbf6f60fcabe7375026b4","936916526486c19890ab9217da73a2298c805481","a62ad652d907c48764488154f567f6a2f3e23626","3d22cec295f1c8c008710cae3171b1379d5e18b8","9fa69b4bcdbd2e93b049de6ba91420da05314292"],"dep_lines":[25,6,9,24,30,31,2,6,8,22,23,1,3,5,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,20,5,5,5,10,5,5,5,30,30,30,30,30,30,30,30,30,30],"dependencies":["torch.fx.experimental.proxy_tensor","torch.utils._pytree","torch._higher_order_ops.utils","torch._subclasses.functional_tensor","torch.fx.graph_module","torch.utils.checkpoint","collections.abc","torch.utils","torch._C","torch._ops","torch._subclasses","math","typing","torch","builtins","abc","enum","torch._C._functorch","torch._tensor","torch.autograd","torch.autograd.function","torch.fx._symbolic_trace","torch.fx.proxy","torch.nn.modules.module","torch.utils._python_dispatch"],"error_lines":[],"hash":"657d37c426f3a819b3ac8f830f178c2b0baadd43","id":"torch._higher_order_ops.flex_attention","ignore_all":true,"interface_hash":"2eeda0cf99d71583f07336030508e95a1ad30722","mtime":1766457564,"options":{"other_options":"ca94ec7c752b811bd68fcc27b867d1b42ae84cef","platform":"win32"},"path":"C:\\Users\\ichirou\\DM_simulation\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\flex_attention.py","plugin_data":null,"size":45469,"suppressed":[],"version_id":"1.19.1"}