{"data_mtime":1766640570,"dep_hashes":["7c4e854dec0c84918e6bd524e880e7c9db90b36c","05d26fa985516f819f2ae1c49b6e1a129ba3d44f","ea96abd1b85d71fd4bacf90e42566b218108a657","7ffe7501d429a800d5f265d45e43cb24d3b6ec5c","953d4e6a392ea00d713e16b8295732026047c508","b22597b98d6d0c07dcff3f737a9e67378528bfa2","25d0bb1f1a05173796e9e1518dd830a3e384de12","706568f1505f727f79da48475350c40bf17377cc","32e3f05ba6a7c2b2d238de68cc5f2f9edda4ab9b","87679607e6afa746f96debbc192e220cba0de5e1","2803465acd2471f91e0d3d33030a43d70bccb294","9402adce881967262cd085ded26bfdcc948db880","03a7f2a0d76cf938e2cfbde51320ea7f7010f907","d87811c1cb05ebb713d9507c441a53fc67aec807","d1973c0e9bc3733a5841305c61ece75df2f37dbb","d85afe14f995e2ab331b7a97cda25985a4cf32d0","286450dfa69445e50787347e1282381910cecf6a","b9b49ee7ee62defded5d266fb47ecc26d50b22b4","7d6a0683091c74e334fe89f9f8692c6aea017dde","3c7f8d8ed52f3be3a8504877e49c26523d2dad76","342ce29e82858e9ddd7320635e59349e74f8d342","936916526486c19890ab9217da73a2298c805481","a62ad652d907c48764488154f567f6a2f3e23626","3d22cec295f1c8c008710cae3171b1379d5e18b8","9fa69b4bcdbd2e93b049de6ba91420da05314292"],"dep_lines":[25,6,9,24,30,31,2,6,8,22,23,1,3,5,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,20,5,5,5,10,5,5,5,30,30,30,30,30,30,30,30,30,30],"dependencies":["torch.fx.experimental.proxy_tensor","torch.utils._pytree","torch._higher_order_ops.utils","torch._subclasses.functional_tensor","torch.fx.graph_module","torch.utils.checkpoint","collections.abc","torch.utils","torch._C","torch._ops","torch._subclasses","math","typing","torch","builtins","abc","enum","torch._C._functorch","torch._tensor","torch.autograd","torch.autograd.function","torch.fx._symbolic_trace","torch.fx.proxy","torch.nn.modules.module","torch.utils._python_dispatch"],"error_lines":[],"hash":"657d37c426f3a819b3ac8f830f178c2b0baadd43","id":"torch._higher_order_ops.flex_attention","ignore_all":true,"interface_hash":"2eeda0cf99d71583f07336030508e95a1ad30722","mtime":1766457564,"options":{"other_options":"2121de79f480fa1cfcd84f3d83993d5dd864dbaa","platform":"win32"},"path":"C:\\Users\\ichirou\\DM_simulation\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\flex_attention.py","plugin_data":null,"size":45469,"suppressed":[],"version_id":"1.19.1"}